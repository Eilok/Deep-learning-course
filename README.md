### 核心逻辑
提出一个自适应量化框架，对模型做量化，加速现有超分辨模型的处理速度。

框架包含两个位映射模块：
- 映射图像到图像级位适应因子
- 获得层级适应因子

### 具体方法
1. 使用非对称均匀量化器-解决激活值分布的高度不对称性
2. 获得准确量化器的方法：
    - 发现：
        1. 层间相对顺序一致：不同层对量化的敏感程度的相对排序在处理不同输入图像时保持稳定
        2. 图像间相对变化一致性
    - 方法：
        1. 分离学习策略
        2. 位宽分配公式(量化器) \
        $ b^{k}_j = b_{base} + b^{I}_j + b^{L}_k $
3. 基于复杂度的图像到位宽映射
    - 图像复杂度计算：平均梯度密度
    - 位宽因子映射公式：\
        $$
        b_I^j = I2B(c(I_L^j)) = 
        \begin{cases} 
        -1, & c(I_L^j) < l_{i2b} \\
        +1, & c(I_L^j) > u_{i2b} \\
        0, & \text{otherwise}
        \end{cases}
        $$
    - 复杂度阈值确定（拿一小部分图像计算复杂度分布，确定 $ l_{i2b} $ 和 $ u_{i2b} $）
4. 基于敏感度的层到位宽映射
    - 量化敏感度计算：将校准图像输入预训练模型，记录每层激活值，并计算其**标准差**，作为敏感度。标准差越大，敏感度越高。
    - 位宽因子映射公式：\
        $$
        b_L^k = L2B(s^k) = 
        \begin{cases} 
        -1, & s^k < l_{i2b}, \\
        +1, & s^k > u_{i2b}, \\
        0, & \text{otherwise}.
        \end{cases}
        $$
    - 敏感度阈值确定（收集所有层的敏感度，确定 $ l_{i2b} $ 和 $ u_{i2b} $ 两个阈值）

    *ps.该步骤可以提前进行，不占用推理时间*
5. 位感知裁剪：根据不同量化位宽动态调整裁剪范围
6. 微调：进一步优化量化网络的参数
    - 像素级重建损失 $ L_{pix} $
    - 层级重建损失 $ L_{skt} $
    - 位宽正则化损失 $ L_{bit} $

### 评估指标
1. PSNR（峰值信噪比）：值越高，越接近高分辨率
2. SSIM（结构相似性）：值越接近1，结构保持越好

### 改进
针对计算图像复杂度部分进行改进：
1. 利用VIT注意力图评估复杂度
2. 使用频域分析方法